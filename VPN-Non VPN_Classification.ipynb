{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ddd8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5f6b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df=pd.read_csv(\"Final Dataset with VPN and Non VPN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b54a69d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count: 623290\n",
      "Column count: 74\n"
     ]
    }
   ],
   "source": [
    "row_count, column_count = combined_df.shape\n",
    "print(\"Row count:\", row_count)\n",
    "print(\"Column count:\", column_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec6587a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "Class\n",
      "VPN        423385\n",
      "NON VPN    199905\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "class_distribution = combined_df['Class'].value_counts()\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d24bc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding, SpatialDropout1D,Dropout\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2cc492b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 74)\n"
     ]
    }
   ],
   "source": [
    "# Assuming combined_df is your DataFrame containing the data\n",
    "vpn_packets = combined_df[combined_df['Class'] == 'VPN'].head(10000)\n",
    "\n",
    "remaining_packets = combined_df[(combined_df['Class'] != 'VPN')].head(10000)\n",
    "\n",
    "# Concatenate the first 200000 VPN packets with the remaining packets\n",
    "final_dataset = pd.concat([vpn_packets, remaining_packets], ignore_index=True)\n",
    "print(final_dataset.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4dade5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ip.proto  tcp.srcport  tcp.dstport  udp.srcport  udp.dstport  tcp.seq   \n",
      "0          17.0          NaN          NaN      15685.0      40002.0      NaN  \\\n",
      "1          17.0          NaN          NaN      40002.0      15685.0      NaN   \n",
      "2          17.0          NaN          NaN      15685.0      40027.0      NaN   \n",
      "3          17.0          NaN          NaN      40027.0      15685.0      NaN   \n",
      "4          17.0          NaN          NaN      23581.0         53.0      NaN   \n",
      "...         ...          ...          ...          ...          ...      ...   \n",
      "19995      17.0          NaN          NaN      33306.0      19305.0      NaN   \n",
      "19996      17.0          NaN          NaN      19305.0      33306.0      NaN   \n",
      "19997      17.0          NaN          NaN      33306.0      19305.0      NaN   \n",
      "19998      17.0          NaN          NaN      19305.0      33306.0      NaN   \n",
      "19999      17.0          NaN          NaN      19305.0      33306.0      NaN   \n",
      "\n",
      "       frame.time_epoch  tcp.stream  ip.flags.df  frame.encap_type  ...   \n",
      "0          1.433357e+09         NaN          1.0                 7  ...  \\\n",
      "1          1.433357e+09         NaN          1.0                 7  ...   \n",
      "2          1.433357e+09         NaN          1.0                 7  ...   \n",
      "3          1.433357e+09         NaN          1.0                 7  ...   \n",
      "4          1.433357e+09         NaN          1.0                 7  ...   \n",
      "...                 ...         ...          ...               ...  ...   \n",
      "19995      1.427724e+09         NaN          1.0                 1  ...   \n",
      "19996      1.427724e+09         NaN          0.0                 1  ...   \n",
      "19997      1.427724e+09         NaN          1.0                 1  ...   \n",
      "19998      1.427724e+09         NaN          0.0                 1  ...   \n",
      "19999      1.427724e+09         NaN          0.0                 1  ...   \n",
      "\n",
      "       ip.fragment.error  tcp.analysis.flags.1  tcp.analysis.keep_alive   \n",
      "0                    NaN                   NaN                      NaN  \\\n",
      "1                    NaN                   NaN                      NaN   \n",
      "2                    NaN                   NaN                      NaN   \n",
      "3                    NaN                   NaN                      NaN   \n",
      "4                    NaN                   NaN                      NaN   \n",
      "...                  ...                   ...                      ...   \n",
      "19995                NaN                   NaN                      NaN   \n",
      "19996                NaN                   NaN                      NaN   \n",
      "19997                NaN                   NaN                      NaN   \n",
      "19998                NaN                   NaN                      NaN   \n",
      "19999                NaN                   NaN                      NaN   \n",
      "\n",
      "       tcp.analysis.window_full  tcp.analysis.window_update   \n",
      "0                           NaN                         NaN  \\\n",
      "1                           NaN                         NaN   \n",
      "2                           NaN                         NaN   \n",
      "3                           NaN                         NaN   \n",
      "4                           NaN                         NaN   \n",
      "...                         ...                         ...   \n",
      "19995                       NaN                         NaN   \n",
      "19996                       NaN                         NaN   \n",
      "19997                       NaN                         NaN   \n",
      "19998                       NaN                         NaN   \n",
      "19999                       NaN                         NaN   \n",
      "\n",
      "       tcp.analysis.zero_window  tcp.analysis.zero_window_probe   \n",
      "0                           NaN                             NaN  \\\n",
      "1                           NaN                             NaN   \n",
      "2                           NaN                             NaN   \n",
      "3                           NaN                             NaN   \n",
      "4                           NaN                             NaN   \n",
      "...                         ...                             ...   \n",
      "19995                       NaN                             NaN   \n",
      "19996                       NaN                             NaN   \n",
      "19997                       NaN                             NaN   \n",
      "19998                       NaN                             NaN   \n",
      "19999                       NaN                             NaN   \n",
      "\n",
      "       frame.cap_len.1  Label    Class  \n",
      "0                   62   CHAT      VPN  \n",
      "1                  510   CHAT      VPN  \n",
      "2                  163   CHAT      VPN  \n",
      "3                   49   CHAT      VPN  \n",
      "4                   64   CHAT      VPN  \n",
      "...                ...    ...      ...  \n",
      "19995               96   VOIP  NON VPN  \n",
      "19996              151   VOIP  NON VPN  \n",
      "19997               85   VOIP  NON VPN  \n",
      "19998              150   VOIP  NON VPN  \n",
      "19999              148   VOIP  NON VPN  \n",
      "\n",
      "[20000 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "unwanted_columns = ['frame.len','tcp.flags.syn','tcp.flags.ack','tcp.flags.push', 'tcp.flags.reset',\\\n",
    "                   'data.len']  # Add all unwanted column names here\n",
    "# Remove unwanted columns from the DataFrame\n",
    "filtered_df = final_dataset.drop(columns=unwanted_columns)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9096991e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Labels:\n",
      "Label\n",
      "3    12739\n",
      "2     6769\n",
      "0      319\n",
      "1      173\n",
      "Name: count, dtype: int64\n",
      "Encoded Class:\n",
      "Class\n",
      "1    10000\n",
      "0    10000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a LabelEncoder object\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Label' column\n",
    "filtered_df['Label'] = label_encoder.fit_transform(filtered_df['Label'])\n",
    "filtered_df['Class'] = label_encoder.fit_transform(filtered_df['Class'])\n",
    " # Display the encoded labels\n",
    "print(\"Encoded Labels:\")\n",
    "print(filtered_df['Label'].value_counts())\n",
    "print(\"Encoded Class:\")\n",
    "print(filtered_df['Class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5786023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NON VPN': 0, 'VPN': 1}\n"
     ]
    }
   ],
   "source": [
    "# Mapping original labels to encoded values\n",
    "label_mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1128f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_df.drop(columns=['Class'])\n",
    "y = filtered_df['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb82f814",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "num_classes = len(encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b4fce43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 67)\n",
      "(16000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68c65027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Impute missing values in the features\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test= imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7f0a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 31, 1)\n"
     ]
    }
   ],
   "source": [
    "x_training_data = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "print(x_training_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3356a62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_4 (Conv1D)           (None, 29, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d_4 (MaxPooling  (None, 14, 32)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_5 (Conv1D)           (None, 12, 64)            6208      \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 6, 64)            0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " simple_rnn_7 (SimpleRNN)    (None, 6, 64)             8256      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 6, 64)             0         \n",
      "                                                                 \n",
      " simple_rnn_8 (SimpleRNN)    (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 22,978\n",
      "Trainable params: 22,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "667/667 [==============================] - 6s 7ms/step - loss: 0.2384 - accuracy: 0.9039 - val_loss: 0.0027 - val_accuracy: 0.9998\n",
      "Epoch 2/10\n",
      "667/667 [==============================] - 5s 8ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0017 - val_accuracy: 0.9998\n",
      "Epoch 3/10\n",
      "667/667 [==============================] - 5s 8ms/step - loss: 0.0157 - accuracy: 0.9953 - val_loss: 0.0019 - val_accuracy: 0.9998\n",
      "Epoch 4/10\n",
      "667/667 [==============================] - 5s 7ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 1.9117e-04 - val_accuracy: 1.0000\n",
      "Epoch 5/10\n",
      "667/667 [==============================] - 3s 5ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 4.0360e-04 - val_accuracy: 0.9998\n",
      "Epoch 6/10\n",
      "667/667 [==============================] - 4s 6ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 3.8466e-05 - val_accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "667/667 [==============================] - 5s 8ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 1.1202e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "667/667 [==============================] - 5s 8ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.0111 - val_accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "667/667 [==============================] - 5s 8ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 4.7460e-04 - val_accuracy: 0.9998\n",
      "Epoch 10/10\n",
      "667/667 [==============================] - 5s 8ms/step - loss: 8.6449e-04 - accuracy: 0.9999 - val_loss: 1.0959e-05 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x221d15b7400>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, SimpleRNN, Dropout\n",
    "\n",
    "# Define input shape based on your data\n",
    "input_shape = (x_training_data.shape[1], 1)  # Shape of your input data assuming it's sequential\n",
    "\n",
    "# Define the number of classes for the output\n",
    "num_classes = 2  # Assuming you have 6 classes for the output\n",
    "\n",
    "# Create the combined RNN-CNN model\n",
    "model = Sequential([\n",
    "    # CNN layers\n",
    "    Conv1D(32, 3, activation='relu', input_shape=input_shape),\n",
    "    MaxPooling1D(2),\n",
    "    Conv1D(64, 3, activation='relu'),\n",
    "    MaxPooling1D(2),\n",
    "    #Flatten(),\n",
    "\n",
    "    # RNN layers\n",
    "    SimpleRNN(units=64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(units=64),\n",
    "    Dropout(0.2),\n",
    "\n",
    "    # Output layer\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=24, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e262af8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_9 (SimpleRNN)    (None, 31, 64)            4224      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 31, 64)            0         \n",
      "                                                                 \n",
      " simple_rnn_10 (SimpleRNN)   (None, 31, 64)            8256      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 31, 64)            0         \n",
      "                                                                 \n",
      " simple_rnn_11 (SimpleRNN)   (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 2)                 130       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,866\n",
      "Trainable params: 20,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "500/500 [==============================] - 7s 12ms/step - loss: 0.0757 - accuracy: 0.9820 - val_loss: 0.0547 - val_accuracy: 0.9880\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.0440 - accuracy: 0.9878 - val_loss: 0.0264 - val_accuracy: 0.9902\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 6s 12ms/step - loss: 0.0309 - accuracy: 0.9899 - val_loss: 0.0211 - val_accuracy: 0.9918\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.0279 - accuracy: 0.9907 - val_loss: 0.0285 - val_accuracy: 0.9908\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.0240 - accuracy: 0.9916 - val_loss: 0.0274 - val_accuracy: 0.9920\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 8s 16ms/step - loss: 0.0239 - accuracy: 0.9920 - val_loss: 0.0171 - val_accuracy: 0.9905\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.0121 - val_accuracy: 0.9958\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.0193 - accuracy: 0.9937 - val_loss: 0.0103 - val_accuracy: 0.9952\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 7s 15ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0093 - val_accuracy: 0.9960\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 7s 14ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 0.0109 - val_accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define input shape based on your data\n",
    "input_shape = (x_training_data.shape[1], 1)  # Shape of your input data\n",
    "\n",
    "# Define the number of classes for the output\n",
    "num_classes = 2  # Assuming you have 6 classes for the output\n",
    "\n",
    "# Create the RNN model\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(units=64, return_sequences=True, input_shape=input_shape),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(units=64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    SimpleRNN(units=64),\n",
    "    Dropout(0.2),\n",
    "    Dense(units=num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "rnn_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Print the model summary\n",
    "rnn_model.summary()\n",
    "\n",
    "# Train the model with early stopping\n",
    "history = rnn_model.fit(X_train, y_train, epochs=10, batch_size=32,\n",
    "                        validation_data=(X_test, y_test), callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe2c5c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0958894563373178e-05\n",
      "Test accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a50ecdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.010884657502174377\n",
      "Test accuracy: 0.9955000281333923\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "score = rnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feaf093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ed08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ccb65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f46f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cf8aef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
